{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['http://ynet.co.il', 'http://google.co.il', 'http://mako.co.il', 'http://walla.co.il', 'http://bankhapoalim.co.il', 'http://bankleumi.co.il', 'http://panet.co.il', 'http://www.gov.il', 'http://yad2.co.il', 'http://globes.co.il']\n"
                    ]
                }
            ],
            "source": [
                "import glob\n",
                "\n",
                "filenames = glob.glob(\"./page_lists/*.txt\")\n",
                "\n",
                "\n",
                "# 定义一个函数，这个函数可以将国家的单独网站拿出来\n",
                "def unique_websites(filepath):\n",
                "    country_code = filepath.split('/')[-1].split('_')[-1][:2].lower()\n",
                "    unique_web = []\n",
                "    web_sites_list = open(filepath).read().split(\"\\n\")\n",
                "    for web in web_sites_list:\n",
                "        if web.split(\".\")[-1] == country_code:\n",
                "            unique_web.append(web)\n",
                "\n",
                "    return unique_web\n",
                "\n",
                "global_unique_websites = []\n",
                "\n",
                "for file in filenames:\n",
                "    unique_web = unique_websites(file)\n",
                "    global_unique_websites.extend(unique_web)\n",
                "\n",
                "print(global_unique_websites[:10])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 将所有国家的文件合并在一起"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['', 'http://txstate.edu', 'http://pasakos.lt', 'http://envia.com', 'http://eats365pos.com', 'http://tvnpass.com', 'http://vprok.ru', 'http://utp.edu.my', 'http://sokit.me', 'http://gazetamapo.al']\n",
                        "56120\n"
                    ]
                }
            ],
            "source": [
                "filenames = glob.glob(\"./page_lists/*.txt\")\n",
                "\n",
                "def get_websites(filepath):\n",
                "    web_sites_list = open(filepath).read().split(\"\\n\")\n",
                "    return web_sites_list\n",
                "\n",
                "global_unique_websites = []\n",
                "\n",
                "for file in filenames:\n",
                "    web_sites = get_websites(file)\n",
                "    global_unique_websites.extend(web_sites)\n",
                "\n",
                "global_unique_websites = list(set(global_unique_websites))\n",
                "\n",
                "print(global_unique_websites[:10])\n",
                "print(len(global_unique_websites))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/zhansu/anaconda3/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
                        "  warnings.warn(msg, UserWarning)\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd \n",
                "\n",
                "\n",
                "df_global_unique = pd.DataFrame({\"websites\":global_unique_websites})\n",
                "\n",
                "def get_counry(row):\n",
                "    return row['websites'].split('.')[-1]\n",
                "\n",
                "def get_domain(row):\n",
                "    return row['websites'].split(\"//\")[-1]\n",
                "\n",
                "# df_global_unique['country'] = df_global_unique.apply(get_counry,axis = 1)\n",
                "# df_global_unique['domain'] = df_global_unique.apply(get_domain,axis = 1)\n",
                "\n",
                "\n",
                "df_global_unique.to_csv(\"global_baseline.csv\",index = None,header=None)\n",
                "\n",
                "# df_global_unique.groupby('country').count()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd \n",
                "\n",
                "def remove_blank(row):\n",
                "    return row.strip()\n",
                "\n",
                "df_country = pd.read_csv(\"country.csv\")\n",
                "\n",
                "df_iii = pd.read_csv(\"/Users/zhansu/program/code/phd_privacy_lost/project_code/common_crawl/internet_inclusivity_index_affordability_ranking_aug_2021.csv\")\n",
                "df_iii.columns = ['rank',\"country_name\",'score']\n",
                "\n",
                "df_iii.merge(df_country, how=\"inner\", on = \"country_name\").to_csv(\"glocality_world.csv\",index = None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_dk = pd.read_csv(\"page_lists/rank_xmlResponse_DK.txt\",names = ['website'])\n",
                "\n",
                "def get_domain(row):\n",
                "    return row['website'].split(\"//\")[-1]\n",
                "df_dk['domain'] = df_dk.apply(get_domain,axis = 1)\n",
                "df_dk.to_csv(\"DK_websites.csv\",index = None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "a47df236d3598d0f23350e496a9dca910dbf23596eb5a1cabebc7b7ebdd2cf16"
        },
        "kernelspec": {
            "display_name": "Python 3.7.3 64-bit ('base': conda)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.3"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
